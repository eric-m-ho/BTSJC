num = num + weights[j];
}
}
error = num/denom;
alpha[i] = log((1-error)/error);
for(z in 1:size){
if(y[z]!=label[z]){
weights[z] = weights[z]*((1-error)/error);
}
}
}
return (list(alpha, allPars))
}
#Cross-Validation
#using 5 weak learners
b=c(1:5);
x = rep(0,5);#average training errors
y = rep(0,5);#test errors
#Generate vector of 40 numbers (20% of 200) from 1 to 200, no duplicates.
#Contains row indices to be used for test case.
randvec = sample(1:200, size = 40, replace = FALSE)
randvec = sort(randvec)
#testset contains the test data
testset = matrix(nrow = 256, ncol = 0)
testset = cbind(testset, uspsdata[,randvec])
#otherdata contains training data (everything other than test data)
otherdata = uspsdata[,-randvec]
#othercl contains classifiers for the training data
othercl = uspscl[-(randvec)]
#putting test set classifiers into testcl from uspscl (only the indices
#corresponding to those in randvec)
testcl= uspscl[randvec]
split = sample(1:5, length(othercl), replace = T)
for(i in 1:5){#number of weak learners
for(j in 1:5){#number of blocks
x_train = otherdata[,split!=j]
y_train = othercl[split!=j]
x_valid = otherdata[,split==j]
y_valid = othercl[split==j]
trainpars = AdaBoost2(x_train, y_train, i)
est = agg_class(x_valid, trainpars[[1]],trainpars[[2]])
res = y_valid - est
error = (length(y_valid)-sum(res==0))/length(y_valid)
x[i] = x[i] + error
}
x[i]=x[i]/5
testpars = AdaBoost2(otherdata, othercl, i)
testest = agg_class(testset, testpars[[1]], testpars[[2]] )
testres = testcl - testest
testerror = (length(testcl)-sum(testest==0))/length(testcl)
y[i] = y[i] + testerror
}
x
y
testset
ncol(testset)
testcl
randvec
uspscl
#Problem 3
#Part 1: train, classify, agg_class
train = function(X, w, y){
denom = sum(w);
parsmatrix = matrix(ncol = 4, nrow = 0);
dimension = nrow(X)
for(j in 1:dimension){
bestthetaerror = 1; #holds best error given j
thetagj = 0; #holds best parameter theta given j
idealm = 0; #holds best parameter m for given j
for(theta in 0: 240){
nump = 0; #numerator of error rate for m>0
numn = 0; #numerator of error rate for m<0
errorp = 0; #error for m>0
errorn = 0; #error for m<0
errortheta = 0; #running track of error
for(i in 1:ncol(X)){#this is for m>0
if(y[i]>0&&X[j,i]<=theta||y[i]<0&&X[j,i]>theta){
nump = nump + w[i];
}
}#end for loop through data vectors
errorp = nump/denom;
errorn = 1 - errorp
if(errorn > errorp){
m = 1;
errortheta = errorp;
}
else{
m = -1;
errortheta = errorn;
}
if(errortheta < bestthetaerror){
bestthetaerror = errortheta;
idealm = m;
thetagj = theta;
}
}#end for loop through theta
vector = c(j, thetagj, idealm, bestthetaerror);
parsmatrix = rbind(parsmatrix, vector);
}#end for loop through j
bestrow = which.min(parsmatrix[,4]);
pars = as.list(parsmatrix[bestrow,-4]);
return(pars);
}#end function
classify = function(X, pars){
label = vector(length = ncol(X));
axis = pars[[1]];
theta = pars[[2]];
m = pars[[3]];
for(i in 1:ncol(X)){
if(X[axis, i]>theta){
if(m>0){
label[i] = 1;
}
else{
label[i] = -1;
}
}
else{
if(m>0){
label[i] = -1;
}
else{
label[i] = 1;
}
}
}
return(label);
}
agg_class = function(X, alpha, allPars){
sum = 0;
num = length(alpha);
for(i in 1: num){
sum = sum + alpha[i]*classify(X, allPars[i,])
}
c_hat = sign(sum);
return(c_hat);
}
#AdaBoost
AdaBoost = function(X, y, B){
size = ncol(X);
weights = rep(1/size, size);
allPars = matrix(ncol = 3, nrow = 0);
alpha = rep(NA, B);
for (i in 1:B){
pars = train(X, weights, y);
allPars = rbind(allPars, pars)
label = classify(X, pars);
denom = sum(weights);
num =0;
for(j in 1:size){
if(y[j] != label[j]){
num = num + weights[j];
}
}
error = num/denom;
alpha[i] = log((1-error)/error);
for(z in 1:size){
if(y[z]!=label[z]){
weights[z] = weights[z]*((1-error)/error);
}
}
}
c_hat = agg_class(X, alpha, allPars)
return (c_hat)
}
#AdaBoost2
#used for CV: does the same procedure but returns the alphas and
#parameters of the resulting boosting classifier.
AdaBoost2 = function(X, y, B){
size = ncol(X);
weights = rep(1/size, size);
allPars = matrix(ncol = 3, nrow = 0);
alpha = rep(NA, B);
for (i in 1:B){
pars = train(X, weights, y);
allPars = rbind(allPars, pars)
label = classify(X, pars);
denom = sum(weights);
num =0;
for(j in 1:size){
if(y[j] != label[j]){
num = num + weights[j];
}
}
error = num/denom;
alpha[i] = log((1-error)/error);
for(z in 1:size){
if(y[z]!=label[z]){
weights[z] = weights[z]*((1-error)/error);
}
}
}
return (list(alpha, allPars))
}
#Cross-Validation
#using 5 weak learners
b=c(1:5);
x = rep(0,5);#average training errors
y = rep(0,5);#test errors
#Generate vector of 40 numbers (20% of 200) from 1 to 200, no duplicates.
#Contains row indices to be used for test case.
randvec = sample(1:200, size = 40, replace = FALSE)
randvec = sort(randvec)
#testset contains the test data
testset = matrix(nrow = 256, ncol = 0)
testset = cbind(testset, uspsdata[,randvec])
#otherdata contains training data (everything other than test data)
otherdata = uspsdata[,-randvec]
#othercl contains classifiers for the training data
othercl = uspscl[-(randvec)]
#putting test set classifiers into testcl from uspscl (only the indices
#corresponding to those in randvec)
testcl= uspscl[randvec]
split = sample(1:5, length(othercl), replace = T)
for(i in 1:5){#number of weak learners
for(j in 1:5){#number of blocks
x_train = otherdata[,split!=j]
y_train = othercl[split!=j]
x_valid = otherdata[,split==j]
y_valid = othercl[split==j]
trainpars = AdaBoost2(x_train, y_train, i)
est = agg_class(x_valid, trainpars[[1]],trainpars[[2]])
res = y_valid - est
error = (length(y_valid)-sum(res==0))/length(y_valid)
x[i] = x[i] + error
}
x[i]=x[i]/5
testpars = AdaBoost2(otherdata, othercl, i)
testest = agg_class(testset, testpars[[1]], testpars[[2]] )
testres = testcl - testest
testerror = (length(testcl)-sum(testres==0))/length(testcl)
y[i] = y[i] + testerror
}
x
y
b
plot(b, x, main="Training Error vs b", xlab = "b", ylab = "Training Error")
plot(b, y, main = "Test Error vs b", xlab = "b", ylab = "Test Error")
curve(exp(-x),from=0,to=4)
x=c(1,2,4)
y=exp(-x)
points(x,y)
words = c("x=1","x=2","x=4")
text(x,y,words)
curve(exp(-x),from=0,to=4)
> x=c(1,2,4)
> y=exp(-x)
> points(x,y)
curve(exp(-x),from=0,to=4)
x=c(1,2,4)
y=exp(-x)
points(x,y)
samples = rexp(256)
alpha = 2
beta = .2
curve(dgamma(shape = 2 + 4, rate = .2+samples[1:4]),from=0, to=4)
curve(dgamma(x,shape = 2 + 4, rate = .2+samples[1:4]),from=0, to=4)
x
curve(dgamma(y,shape = 2 + 4, rate = .2+samples[1:4]),from=0, to=4)
x = seq(0:4, by = 0.01)
x = seq(from=0, to=4, by = 0.01)
curve(dgamma(x,shape = 2 + 4, rate = .2+samples[1:4]),from=0, to=4)
clear
clear()
samples
samples[1:4]
curve(dgamma(x,shape = 2 + 4, rate = .2+sum(samples[1:4])),from=0, to=4)
curve(dgamma(x,shape = 2 + 4, rate = .2+sum(samples[1:4])),from=0, to=4,col="blue")
curve(dgamma(x,shape = 2 + 4, rate = .2+sum(samples[1:4])),from=0, to=4,col="blue",ylab = "probability")
curve(dgamma(x,shape = 2 + 8, rate = .2+sum(samples[1:8])),from=0, to=4,col="red",add=TRUE)
curve(dgamma(x,shape = 2 + 16, rate = .2+sum(samples[1:16])),from=0, to=4,col="green",add=TRUE)
curve(dgamma(x,shape = 2 + 256, rate = .2+sum(samples[1:256])),from=0, to=4,col="black",add=TRUE)
sum(samples[1:4])
plot(ylim=c(0,2))
curve(dgamma(x,shape = 2 + 4, rate = .2+sum(samples[1:4])),from=0,
to=4,col="blue",ylab = "probability")
curve(dgamma(x,shape = 2 + 8, rate = .2+sum(samples[1:8])),from=0,
to=4,col="red",add=TRUE)
curve(dgamma(x,shape = 2 + 16, rate = .2+sum(samples[1:16])),from=0,
to=4,col="green",add=TRUE)
curve(dgamma(x,shape = 2 + 256, rate = .2+sum(samples[1:256])),from=0,
to=4,col="black",add=TRUE)
curve(dgamma(x,shape = 2 + 256, rate = .2+sum(samples[1:256])),from=0,
to=4,col="black",ylab = "probability")
curve(dgamma(x,shape = 2 + 4, rate = .2+sum(samples[1:4])),from=0,
to=4,col="blue",add=TRUE)
curve(dgamma(x,shape = 2 + 8, rate = .2+sum(samples[1:8])),from=0,
to=4,col="red",add=TRUE)
curve(dgamma(x,shape = 2 + 16, rate = .2+sum(samples[1:16])),from=0,
to=4,col="green",add=TRUE)
curve(dgamma(x,shape = 2 + 256, rate = .2+sum(samples[1:256])),from=0,
to=4,col="black",ylab = "density")
curve(dgamma(x,shape = 2 + 4, rate = .2+sum(samples[1:4])),from=0,
to=4,col="blue",add=TRUE)
curve(dgamma(x,shape = 2 + 8, rate = .2+sum(samples[1:8])),from=0,
to=4,col="red",add=TRUE)
curve(dgamma(x,shape = 2 + 16, rate = .2+sum(samples[1:16])),from=0,
to=4,col="green",add=TRUE)
curve(dgamma(x,shape = 2 + 256, rate = .2+sum(samples[1:256])),from=0,
to=4,col="black",ylab = "density")
curve(dgamma(x,shape = 2 + 4, rate = .2+sum(samples[1:4])),from=0,
to=4,col="blue",add=TRUE)
curve(dgamma(x,shape = 2 + 8, rate = .2+sum(samples[1:8])),from=0,
to=4,col="red",add=TRUE)
curve(dgamma(x,shape = 2 + 16, rate = .2+sum(samples[1:16])),from=0,
to=4,col="green",add=TRUE)
legend('topright', c("n=4","n=8", "n=16", "n=256") ,
lty=1, col=c('blue', 'red', 'green',' black'), bty='n', cex=.75)
curve(dgamma(x,shape = 2 + 256, rate = .2+sum(samples[1:256])),from=0,
to=4,col="black",xlab = "theta",ylab = "density")
curve(dgamma(x,shape = 2 + 4, rate = .2+sum(samples[1:4])),from=0,
to=4,col="blue",add=TRUE)
curve(dgamma(x,shape = 2 + 8, rate = .2+sum(samples[1:8])),from=0,
to=4,col="red",add=TRUE)
curve(dgamma(x,shape = 2 + 16, rate = .2+sum(samples[1:16])),from=0,
to=4,col="green",add=TRUE)
legend('topright', c("n=4","n=8", "n=16", "n=256") ,
lty=1, col=c('blue', 'red', 'green',' black'), bty='n', cex=.75)
cumsum(1:4)
cumprod(1:4)
4:2
cummin(1:4)
cummax(1:4)
library(nycflights13)
library(dplyr)
install.packages("dplyr")
library(dplyr)
library(MASS)
data()
UCBAdmissions
airquality
Titanic
Animals
filter(Animals, body>5)
arrange(Animals, brain)
select(Animals, brain)
select(Animals, body)
rename(Animals, brain = BRAINS)
rename(Animals, BRAINS = brain)
mutate(Animals, sum = brain + body)
summarise(Animals, brain)
library(data.table)
install.packages("shiny")
library(shiny)
runExample("01_hello")
setwd("C:/Users/Eric/Desktop/BTSJC")
library(data.table)
library(dplyr)
library(ggplot2)
setwd("C:/Users/Eric/Desktop/BTSJC")
data<-fread("BTSJCData.csv")
View(data)
library(data.table)
library(dplyr)
library(ggplot2)
setwd("C:/Users/Eric/Desktop/BTSJC")
BTdata<-fread("BTSJCData.csv")
View(BTdata)
p=ggplot(data = BTdata, aes(x = Time (minutes), y = Math Change)) +
geom_smooth(method='lm')
p=ggplot(data = BTdata, aes(x = 'Time (minutes)', y = 'Math Change')) +
geom_smooth(method='lm')
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change)) +
geom_smooth(method='lm')
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change)) + geom_smooth(method='lm')
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change))
+ geom_smooth(method='lm')
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change))
+geom_smooth(method='lm')
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change))
+geom_smooth(method='lm')
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change))
+geom_smooth(method='lm')
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change))
+geom_smooth(method='lm')
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change))
+geom_smooth(method='lm')
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change))
+geom_smooth(method='lm')
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change))
+geom_smooth(method='lm')
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change))+geom_smooth(method='lm')
objects(BTData)
BTData$Percentile
library(data.table)
library(dplyr)
library(ggplot2)
setwd("C:/Users/Eric/Desktop/BTSJC")
BTdata<-fread("BTSJCData.csv")
View(BTdata)
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change))+geom_smooth(method='lm')
BTData$Percentile
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change))
p=ggplot(data = BTdata, aes(x = BTData$Percentile, y = BTData$Math Change))
View(BTData)
library(data.table)
library(dplyr)
library(ggplot2)
setwd("C:/Users/Eric/Desktop/BTSJC")
BTdata<-fread("BTSJCData.csv")
View(BTdata)
p=ggplot(data = BTdata, aes(x = BTData$Percentile, y = BTData$Math Change))
BTdata
names(BTData)
BTData
BTdata
p=ggplot(data = BTdata, aes(x = BTdata$Percentile, y = BTdata$Math Change))
p=ggplot(data = BTdata, aes(x = Percentile, y = Math Change))
names(BTdata)
BTdata$Math Change
BTdata$Math\ Change
BTdata$Math\s Change
BTdata$Math\sChange
BTdata$Percentile
library(data.table)
library(dplyr)
library(ggplot2)
setwd("C:/Users/Eric/Desktop/BTSJC")
BTdata<-fread("BTSJCData.csv")
View(BTdata)
p=ggplot(data = BTdata, aes(x = Time, y = MathChange))
p=ggplot(data = BTdata, aes(x = Time, y = MathChange))
p=ggplot(data = BTdata, aes(x = Time, y = MathChange))
p=ggplot(data = BTdata, aes(x = Time, y = MathChange))
BTdata$Math\s Change
p=ggplot(data = BTdata, aes(x = Time, y = MathChange))
p=ggplot(data = BTdata, aes(x = Time, y = MathChange))+
geom_point(shape=1) +
geom_smooth(method=lm)
p=ggplot(data = BTdata, aes(x = BTdata$Time, y = BTdata$MathChange))+
geom_point(shape=1) +
geom_smooth(method=lm)
p
p=ggplot(data = BTdata, aes(x = Time, y = MathChange))+
geom_point(shape=1) +
geom_smooth(method=lm)
ggplot(data = BTdata, aes(x = Time, y = MathChange))+
geom_point(shape=1) +
geom_smooth(method=lm)
ggplot(data = BTdata, aes(x = Time, y = MathChange))+
geom_point(shape=0) +
geom_smooth(method=lm)
ggplot(data = BTdata, aes(x = Time, y = MathChange))+
geom_point(shape=3) +
geom_smooth(method=lm)
ggplot(data = BTdata, aes(x = Time, y = MathChange))+
geom_point(shape=3) +
geom_smooth(method=lm)
+ labs(x='Time (minutes)',y='Change in Math Scores') + ggtitle("Time vs. Change in Math Scores")
ggplot(data = BTdata, aes(x = Time, y = MathChange))+
geom_point(shape=3) +
geom_smooth(method=lm)+labs(x='Time (minutes)',y='Change in Math Scores') + ggtitle("Time vs. Change in Math Scores")
ggplot(data = BTdata, aes(x = Time, y = MathChange))+
geom_point(shape=3) +
geom_smooth(method=lm)+labs(x='Time (minutes)',y='Change in Math Scores') +
ggtitle("Time vs. Change in Math Scores")
title: "BTSJC"
#Time vs. Percentile
ggplot(data = BTdata, aes(x = Time, y = Percentile))+
geom_point(shape=3) +
geom_smooth(method=lm)+labs(x='Time (minutes)',y='Percentile') +
ggtitle("Time vs. Percentile")
#Time vs. Percentile
ggplot(data = BTdata, aes(x = Time, y = PercentileRank))+
geom_point(shape=3) +
geom_smooth(method=lm)+labs(x='Time (minutes)',y='PercentileRank') +
ggtitle("Time vs. PercentileRank")
BTdata2<-fread("BTSJCDataRead.csv")
View(BTdata2)
View(BTdata2)
BTdata2<-fread("BTSJCDataRead.csv")
View(BTdata2)
ggplot(data = BTdata, aes(x = MathChange, y = ReadingChange))+
geom_point(shape=3) +
geom_smooth(method=lm)+labs(x='Change in Math Scores',y='Change in Reading Scores') +
ggtitle("Change in Math Scores vs. Change in Reading Scores")
ggplot(data = BTdata2, aes(x = MathChange, y = ReadingChange))+
geom_point(shape=3) +
geom_smooth(method=lm)+labs(x='Change in Math Scores',y='Change in Reading Scores') +
ggtitle("Change in Math Scores vs. Change in Reading Scores")
#Time vs. MathChange
ggplot(data = BTdata, aes(x = Time, y = MathChange))+
geom_point(shape=3) +
geom_smooth(method=lm)+labs(x='Time (minutes)',y='Change in Math Scores') +
ggtitle("Time vs. Change in Math Scores")
#Time vs. Percentile
ggplot(data = BTdata, aes(x = Time, y = PercentileRank))+
geom_point(shape=3) +
geom_smooth(method=lm)+labs(x='Time (minutes)',y='PercentileRank') +
ggtitle("Time vs. PercentileRank")
p=ggplot(data = BTdata, aes(x = Students, y = Algebra)) +
geom_bar()
p
#stacked bar graph
p=ggplot(data = BTdata, aes(x = Student, y = Algebra)) +
geom_bar()
p
keeps <- c("Algebra", "Functions", "Geometry", "Numbers.Operations", "Statistics.Probability")
cordata <- BTdata[keeps]
cor(cordata)
keeps <- c("Algebra", "Functions", "Geometry", "Numbers.Operations", "Statistics.Probability")
cordata <- BTdata[,keeps]
cor(cordata)
View(cordata)
cordata <- BTdata[,-2:6]
View(cordata)
cordata <- BTdata[,-(2:6)]
View(cordata)
keeps <- c("Algebra", "Functions", "Geometry", "Numbers.Operations", "Statistics.Probability")
cordata <- subset(BTdata, select = keeps)
View(cordata)
cor(cordata)
